---
title: "Multiple Linear Regression"
subtitle: "Lecture 15"
date: "2025-06-05"
format: 
  revealjs:
    output-file: 15-mult-reg-slides.html
    pdf-separate-fragments: true
---

```{r}
#| include: false
library(tidyverse)
library(tidymodels)
library(fivethirtyeight)
library(datasauRus)
movie_scores <- fandango |>
  rename(
    critics = rottentomatoes, 
    audience = rottentomatoes_user
  )

# Treat 'am' as a factor (categorical predictor)
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))

todays_ae <- "ae-12-modeling-penguins"

```

```{r}
#| include: false
movie_scores <- movie_scores %>%
  mutate(imdb_cat = case_when(
    imdb < 6.3 ~ "Low",
    imdb < 7.4 ~ "Med",
    TRUE ~ "High"
  ))
# Fit model: critic rating as outcome, audience level as predictor
model <- lm(audience ~ imdb_cat, data = movie_scores)
summary(model)

# Plot
ggplot(movie_scores, aes(x = imdb_cat, y = audience)) +
  geom_boxplot(fill = "orchid") +
  geom_jitter(width = 0.1, alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", color = "darkred", size = 3) +
  labs(title = "Critic Score by Audience Rating Level",
       x = "Audience Rating Category",
       y = "Metacritic Score") +
  theme_minimal()
```

## Announcements

-   Office hours today: 1-3pm; old chem 203

-   Math warning: logarithms; natural log

-   Let me know if your Milestone 2 is ready to grade!

## Simple Linear Regression

-   A single quantitative $x$ and $y$

-   Population Model:

    $$
    Y = \beta_0 + \beta_1 X + \epsilon
    $$

-   Regression Line:

    $$
    \hat{Y} = b_0 + b_1 X
    $$

# Regression with Categorical Variables

## Regression with Categorical Variables {.smaller}

*It's possible to want to model an outcome based on a categorical predictor:*

$$ Y = \beta_0 + \beta_1 X + \epsilon$$

What does this even mean when $x$ is categorical ???

# Movie Example

## Example Data

```{r}
#| echo: false
movie_scores |>
  select(critics, audience, imdb_cat)
```

## Example Data: Visualization {.smaller}

```{r}
#| echo: false

ggplot(movie_scores, aes(x = imdb_cat, y = audience)) +
  geom_boxplot(fill = "orchid") +
  #geom_jitter(width = 0.1, alpha = 0.5) +
  #stat_summary(fun = mean, geom = "point", color = "darkred", size = 3) +
  labs(title = "Critic Score by Audience Rating Level",
       x = "Audience Rating Category",
       y = "Metacritic Score") +
  theme_minimal()
```

## Let's just try it... {.smaller}

```{r}
movies_fit <- linear_reg() |>
  fit(audience ~ imdb_cat, data = movie_scores)

tidy(movies_fit)
```

What's going on??

## What's going on? {.smaller}

Variable `imdb_cat` can take values *high, med,* or *low.* We want to model variable `audience` based on `imdb_cat`.

. . .

We tell R to fit `audience ~ imdb_cat` ... now what?

. . .

[We get ***dummy variables!!!***]{style="background-color: #fcefb3"}

## Dummy Variables {.smaller}

::: columns
::: {.column width="50%"}
| audience | imdb_cat |
|----------|----------|
| 70       | high     |
| 40       | low      |
| 50       | med      |
| 80       | high     |
:::
:::

## Dummy Variables {.smaller}

::: columns
::: {.column width="50%"}
| audience | imdb_cat |
|----------|----------|
| 70       | high     |
| 40       | low      |
| 50       | med      |
| 80       | high     |
:::

::: {.column width="50%"}
| audience | imdb_cat | high | low | med |
|----------|----------|------|-----|-----|
| 70       | high     |      |     |     |
| 40       | low      |      |     |     |
| 50       | med      |      |     |     |
| 80       | high     |      |     |     |
:::
:::

. . .

::: callout-important
In a given row, only *one* of the dummy variables for a given categorical variable can equal 1.
:::

## Write the regression output: {.smaller}

Using the categorical variable?

$$
\widehat{audience} = b_0 + b_1 \times imdb\_cat
$$

<br><br><br>

‚ùå WRONG ‚ùå üõë DON'T DO THIS üõë ‚ùóSERIOUSLY ‚ùóüíî Don't make me sad :( üíî

## What will a regression output look like? {.smaller}

Use the dummy variables!!

$$
\widehat{audience} = b_0 + b_1 \times low + b_2  \times med
$$

## What will a regression output look like? {.smaller}

Use the dummy variables!!

$$
\widehat{audience} = b_0 + b_1 \times low + b_2 \times med
$$

<br><br><br>

::: callout-important
All levels except the **baseline level** will show up in the output.
Here, high is the **baseline level.** You will be able to identify the baseline by looking at the data and the output!
:::

## Interpret the output: {.smaller}

$$
\widehat{audience} = b_0 + b_1 \times low + b_2 \times med
$$

-   (Intercept) $b_0$ ?

<br>

-   (Slope) $b_1$ ?

<br>

-   (Slope) $b_2$ ?

## Let's plug in some numbers: {.smaller}

```{r}
movies_fit <- linear_reg() |>
  fit(audience ~ imdb_cat, data = movie_scores)

tidy(movies_fit)
```

<br>

$$
\widehat{audience} = 85.1 -45.8 \times low -21.6 \times med
$$

## Interpretation with numbers: {.smaller}

$$
\widehat{audience} = 85.1 -45.8 \times low -21.6 \times med
$$

<br>

-   Expected audience score of high IMDB rating movies: 85.1

-   Movies with low IMDB ratings are expected to have, on average, audience scores 45.8 points lower than movies with high IMDB ratings

-   Movies with medium IMDB ratings are expected to have, on average, audience scores 21.6 points lower than movies with high IMDB ratings

# In General

## Generally: {.smaller}

Predicting [continuous outcome]{style="background-color: #fcefb3"} $y$ using [categorical explanatory variable]{style="background-color: #fcefb3"} $x$ with levels $cat_0, \ldots cat_L$:

## Generally: {.smaller}

Predicting [continuous outcome]{style="background-color: #fcefb3"} $y$ using [categorical explanatory variable]{style="background-color: #fcefb3"} $x$ with levels $cat_0, \ldots cat_L$:

$$
\hat{y} = b_0 + b_1 \times cat_1 + b_2 \times cat_2 \ldots + b_L \times cat_L
$$

## Generally: {.smaller}

Predicting [continuous outcome]{style="background-color: #fcefb3"} $y$ using [categorical explanatory variable]{style="background-color: #fcefb3"} $x$ with levels $cat_0, \ldots cat_L$:

$$
\hat{y} = b_0 + b_1 \times cat_1 + b_2 \times cat_2 \ldots + b_L \times cat_L
$$

-   $b_0$ : On average, expected $y$ for an entry of **baseline level** $cat_0$

<br>

-   $b_1$: On average, we expect the $y$ for an observation of level $cat_1$ to be be $b_1$ larger (smaller if negative) than a baseline $cat_0$ observation <br>

<br>

-   and so on....

## Back to AE-12! {.smaller}

# Multiple Predictors

## More than 1 predictor variable {.smaller}

-   So far, we have looked at models with one predictor variable. What if we want multiple?

-   First, I will show what happens with one of each type of predictor - numerical and categorical

-   We can also have:

    -   More than 2 predictors (might appear in your projects! will appear in real life!)

    -   Different combinations of predictor types (all numerical, all categorical, some of each...)

## Approach: {.smaller}

-   Teach by example

-   You might see a case in lab that we haven't seen in class - don't panic!
    The same concepts will apply.

# Penguins Example

## Penguins so far {.smaller}

-   So far, we have seen body mass predicted by:

    -   Flipper length

    -   Island

-   What if we should use both for prediction??

## Penguins Data Visualization {.smaller}

Both of these use `flipper_length_mm` *and* `island` to predict `body_mass_g`:

```{r}
#| include: false
bm_fl_island_fit <- linear_reg() |>
  fit(body_mass_g ~ flipper_length_mm + island, data = penguins)

tidy(bm_fl_island_fit)
```

```{r}
#| label: additive-interaction-viz
#| layout-ncol: 2
#| echo: false
#| fig-asp: 1
#| warning: false
#| message: false


# Plot A
bm_fl_island_fit <- linear_reg() |>
  fit(body_mass_g ~ flipper_length_mm + island, data = penguins)
bm_fl_island_aug <- augment(bm_fl_island_fit, new_data = penguins)
# Plot A - Additive model
ggplot(
  bm_fl_island_aug, 
  aes(x = flipper_length_mm, y = body_mass_g, color = island)
) +
  geom_point(alpha = 0.5) +
  geom_smooth(aes(y = .pred), method = "lm") +
  labs(
    title = "Plot A - Additive model",
    x = "Flipper Length (mm)",
    y = "Body Mass (g)",
    color = "Island"
  ) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 18, face = "bold"),
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)
  )

# Plot B - Interaction model
ggplot(
  penguins, 
  aes(x = flipper_length_mm, y = body_mass_g, color = island)
) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(
    title = "Plot B - Interaction model",
    x = "Flipper Length (mm)",
    y = "Body Mass (g)",
    color = "Island"
  ) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 18, face = "bold"),
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)
  )

```

## The additive model: parallel lines, one for each island {.smaller}

```{r}
bm_fl_island_fit <- linear_reg() |>
  fit(body_mass_g ~ flipper_length_mm + island, data = penguins)

tidy(bm_fl_island_fit)
```

$$
\begin{aligned}
\widehat{body~mass} = -4625 &+ 44.5 \times flipper~length \\
&- 262 \times Dream \\
&- 185 \times Torgersen
\end{aligned}
$$

## Where do the three lines come from? {.smaller}

$$
\begin{aligned}
\widehat{body~mass} = -4625 &+ 44.5 \times flipper~length \\
&- 262 \times Dream \\
&- 185 \times Torgersen
\end{aligned}
$$

. . .

If penguin is from Biscoe, Dream = 0 and Torgersen = 0:

. . .

$$
\begin{aligned}
\widehat{body~mass} = -4625 &+ 44.5 \times flipper~length
\end{aligned}
$$

. . .

If penguin is from Dream, Dream = 1 and Torgersen = 0:

. . .

$$
\begin{aligned}
\widehat{body~mass} = -4887 &+ 44.5 \times flipper~length
\end{aligned}
$$

. . .

If penguin is from Torgersen, Dream = 0 and Torgersen = 1:

. . .

$$
\begin{aligned}
\widehat{body~mass} = -4810 &+ 44.5 \times flipper~length
\end{aligned}
$$

## How do we interpret this in English? {.smaller}

$$
\begin{aligned}
\widehat{body~mass} = -4625 &+ 44.5 \times flipper~length \\
&- 262 \times Dream \\
&- 185 \times Torgersen
\end{aligned}
$$

-   Intercept: We expect, [on average]{.underline}, penguins from **Biscoe** island with **0mm flipper length** to weigh **-4625 grams**

. . .

-   Slope (flipper length) : ***Holding island constant,*** we expect, on average, a **1mm** increase in flipper length corresponds to a **44.5g** increase in body mass

. . .

-   Slope (dream) : ***Holding flipper length constant,*** we expect, [on average]{.underline}, a penguin from the **Dream island** to be **262g lighter** than a penguin from **Biscoe** island.

. . .

-   Slope (torgersen) : You try!


## Prediction

```{r}
new_penguin <- tibble(
  flipper_length_mm = 200,
  island = "Torgersen"
)

predict(bm_fl_island_fit, new_data = new_penguin)
```

## The interaction model: different slopes for each island {.smaller}

```{r}
bm_fl_island_int_fit <- linear_reg() |>
  fit(body_mass_g ~ flipper_length_mm * island, data = penguins)

tidy(bm_fl_island_int_fit) |> select(term, estimate)
```

. . .

$$
\begin{aligned}
\widehat{body~mass} = -5464 + 48.5 \times flipper~length &+ 3551 \times Dream \\
&+ 3218 \times Torgersen \\
&- 19.4 \times flipper~length*Dream \\
&- 17.4 \times flipper~length*Torgersen
\end{aligned}
$$
