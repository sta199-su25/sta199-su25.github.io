---
title: "Model Selection"
subtitle: "Lecture 17"
date: "2025-06-10"
format: 
  revealjs:
    output-file: 17-model-select-slides.html
    pdf-separate-fragments: true
---

```{r}
#| include: false
library(tidyverse)
library(tidymodels)
library(fivethirtyeight)
library(datasauRus)
library(scatterplot3d)

movie_scores <- fandango |>
  rename(
    critics = rottentomatoes, 
    audience = rottentomatoes_user
  )

# Treat 'am' as a factor (categorical predictor)
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))

todays_ae <- "ae-12-modeling-penguins"

```

```{r}
#| include: false
movie_scores <- movie_scores %>%
  mutate(imdb_cat = case_when(
    imdb < 6.3 ~ "Low",
    imdb < 7.4 ~ "Med",
    TRUE ~ "High"
  )) 
# Fit model: critic rating as outcome, audience level as predictor
model <- lm(audience ~ imdb_cat, data = movie_scores)
summary(model)

# Plot
ggplot(movie_scores, aes(x = imdb_cat, y = audience)) +
  geom_boxplot(fill = "orchid") +
  geom_jitter(width = 0.1, alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", color = "darkred", size = 3) +
  labs(title = "Critic Score by Audience Rating Level",
       x = "Audience Rating Category",
       y = "Metacritic Score") +
  theme_minimal()
```

## While you wait... {.smaller}

Open up/keep working on AE13!
(Goal: fit the interaction effects model).

## Announcements {.smaller}

-   Office hours today: 3:30 - 5:30

-   Lab 4 Q8 part d: challenge!

-   Midterm scores are posted on gradescope: come by office hours or schedule a meeting with me to see your in-class exam!

## Grading Reminders{.smaller}

-   Labs are equally weighted and the lowest is dropped

-   Midterm is worth 20% of your final grade

-   Final is worth 20% of your final grade

-   ***New policy:** If you score better on the final exam than the midterm, we will weight the final exam higher in your final grade calculation.*

# Let us help you!!!

No question is too big or too small.
Seriously!!

## So many models...{.smaller}

-   We've seen a bunch of different linear models for predicting continuous outcomes

-   How can we tell how good they are?
    How can we choose between models?

## Recall: Residuals{.smaller}

```{r}
#| message: false
#| echo: false
#| fig-align: center
m <- lm(audience ~ critics, data = movie_scores)
ggplot(movie_scores, aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "#325b74", se = FALSE, linewidth = 1.5) +
  geom_segment(aes(x = critics, xend = critics, y = audience, yend = predict(m)), color = "steel blue") +
  labs(x = "Critics Score", y = "Audience Score") +
  theme(legend.position = "none")
```

## Recall: Least squares line{.smaller}

The residual for the $i^{th}$ observation is

$$e_i = \text{observed} - \text{predicted} = y_i - \hat{y}_i$$

. . .

The sum of squared residuals is

$$e^2_1 + e^2_2 + \dots + e^2_n$$

. . .

The least squares line is the one that minimizes the sum of squared residuals

## The concept still applies!{.smaller}

-   Each model we fit since simple linear regression has minimized a sum of squared residuals.

. . .

-   Even if we have more than one $x$ (explanatory variable), we still predict one $\hat{Y}$.

. . .

-   The residual for the $i^{th}$ observation is still

$$e_i = \text{observed} - \text{predicted} = y_i - \hat{y}_i$$ 


. . . 

-   Reminder: use `augment` to get predictions and residuals

## Example{.smaller}

```{r}
#| echo: false
#| warning: false

bm_fl_island_fit <- linear_reg() |>
  fit(body_mass_g ~ flipper_length_mm + island, data = penguins)
bm_fl_island_aug <- augment(bm_fl_island_fit, new_data = penguins)
ggplot(
  bm_fl_island_aug, 
  aes(x = flipper_length_mm, y = body_mass_g, color = island)
) +
  geom_point(alpha = 0.5) +
  geom_segment(
    aes(x = flipper_length_mm, xend = flipper_length_mm,
        y = body_mass_g, yend = .pred),
    color = "grey50", alpha = 0.5
  ) +
  geom_smooth(aes(y = .pred), method = "lm") +
  labs(
    title = "Additive model with residuals",
    x = "Flipper Length (mm)",
    y = "Body Mass (g)",
    color = "Island"
  ) +
  theme(
    legend.position = "bottom"
  )

```

## How do we pick between our models? {.smaller}

-   Over the past few days, we have fit a ton of linear models to predict penguins' body mass.

    -   Simple linear regression with flipper length

    -   Regression with island

    -   Additive model with island and flipper length

    -   Interaction model with island and flipper length

. . .

-   Wouldn't it be nice if there was some score that would tell us which is the "best"??

## Recall: R (no, not the language) {.smaller}

::: incremental
-   Recall: Correlation (R) is a value between -1 and 1 that tells us how strong of a linear relationship two variables haves
-   Now: $R^2$ (between 0 and 1) gives the *proportion of variability in the outcome explained by the model*
-   $R^2$ is useful for quantifying the fit of a given model...
-   ... but $R^2$ *always goes up* every time you add *any* predictor to a model, even if that predictor is silly and useless.
:::

## Adjusted $R^2$ {.smaller}

::: incremental
-   Adjusted $R^2$ is an... adjusted version of $R^2$ that penalized the number of predictors in the model
-   This makes it very useful for comparing models!
-   Philosophically, we want a model that *both:*
    -   Fits/predicts well *and...*
    -   Is as simple as possible (so we can understand it)
-   ***Idea: Occam's razor -*** when faced with many explanations/models, we should choose the least complex one that fits the data well.
:::

## How to implement? {.smaller}

Use the function `glance` to compute $R^2$ and adjusted $R^2$:

```{r}
glance(bm_fl_island_fit)
```
## How to compare?{.smaller}

Just flipper length: 
```{r}
#| echo: false

glance(lm(body_mass_g ~ flipper_length_mm, data = penguins))
```

Just island : 
```{r}
#| echo: false

glance(lm(body_mass_g ~ island, data = penguins))
```
## How to compare?{.smaller}

Additive model:
```{r}
#| echo: false

glance(lm(body_mass_g ~ flipper_length_mm + island, data = penguins))
```

Interaction model:

```{r}
#| echo: false

glance(lm(body_mass_g ~ flipper_length_mm * island, data = penguins))
```

## Practice {.smaller}

-  Use AE-13  to practice!

-  Solutions will be posted today

# A note about (multiple) linear regression
Think about in your projects!

## Why use more variables?{.smaller}

:::incremental
- Real-world outcomes are influenced by **many factors**
- Multiple regression lets us:
  - Include more explanatory variables
  - **Control for** variables that might confound relationships
- This helps isolate the **effect of interest**
:::


## Example: Predicting Wages {.smaller}

You want to understand how **gender** affects wages.

```r
wage ~ gender
```

This tells you the **overall difference**, but doesn't control for **education** or **experience**.

---

## Add control variables {.smaller}

```r
wage ~ gender + education + experience
```

Now you're comparing:

> People with the **same education and experience**  
> But different gender

More fair, more realistic, more useful!

---

## Key idea: Controlling for a variable {.smaller}

> Holding a variable **constant** to isolate the effect of another

You're asking:

> "What is the effect of gender **if education and experience are the same**?"

This is what we mean by **controlling for** variables.

---

## Why this matters {.smaller}

Without controlling, we might:

:::incremental
- Overstate or understate effects
- Confuse correlation with causation
- Miss important patterns

:::

. . . 

Multiple regression gives us a better picture of **how the world really works**.


## Takeaway {.smaller}

When doing data analysis, think about what variables might be related to both your outcome and your explanatory variables!

# Projects

## Talk about:

-  Milestone 2 feedback

-  Milestone 3/4/5 requirements

## Key reminders:

-  use `#| echo: false` in code chunks

-  make sure the website renders!!!!

-  READ THE REQUIREMENTS CAREFULLY!!!

-  COME TO OFFICE HOURS!!!

