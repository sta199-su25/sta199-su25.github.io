{
  "hash": "ad8408d4f9dfa3eb11e76c36d8e67695",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"More logistic regression\"\nsubtitle: \"Lecture 19\"\ndate: \"2025-6-19\"\nformat: \n  revealjs:\n    output-file: 19-logistic-2-slides.html\n    pdf-separate-fragments: true\nauto-stretch: false\n---\n\n## While you wait... {.smaller}\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n::: appex\n-   Go to your `ae` project in RStudio.\n\n-   Make sure all of your changes up to this point are committed and pushed, i.e., there's nothing left in your Git pane.\n\n-   Click Pull to get today's application exercise file: *ae\\-14\\-spam\\-filter\\.qmd*.\n\n-   Wait till the you're prompted to work on the application exercise during class before editing the file.\n:::\n\n## Announcements\n\n-   Office hours tomorrow will be about 20 mins short (1:00 - 2:40).\n    I will be there a little before 1:00 if you want to come early!\n\n-   Make appointment to see in-class exams/talk through problems you're stuck on.\n    Remember, final exam is cumulative!!\n\n## Project Reminders\n\n-   Milestone 3 due Friday night!!\n\n-   Once your project website renders, **you still need to push** for the changes to show up!!!\n\n## Logistic Regression: Recap {.smaller}\n\n*Goal*: modelling/predicting ***binary*** outcome $y$\n\n-   Idea: Model the probability $p$ that $y = 1$\n\n. . .\n\n-   S-curve for the probability of success $p=P(y=1)$:\n\n$$\n    \\hat{p} = \\frac{e^{b_0+b_1x}}{1+e^{b_0+b_1x}}.\n   $$\n\n. . .\n\n-   Linear model for the log-odds:\n\n$$\n    \\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right) = b_0+b_1x.\n  $$\n\n## R syntax is mostly unchanged {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimple_logistic_fit <- logistic_reg() |>\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(simple_logistic_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  <chr>            <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n```\n\n\n:::\n:::\n\n\n. . .\n\nFitted equation for the log-odds:\n\n$$\n\\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)\n=\n-2.27\n+\n0.000272\\times exclaim~mess\n$$\n\n. . .\n\nInterpretations are strange and delicate.\n\n## Questions??? Review??? Anything?! {.smaller}\n\n## Let's Practice\n\nAE-14: Watch now, fill in later (optional!)\n\n## Goal {.smaller}\n\n-   We will build a spam filter from email data\n-   The data come from incoming emails in David Diez's (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012\n-   User number of exclamation marks in an email address (`exclaim_mess`) to predict whether or not the email is spam (`spam`: 1 if spam; 0 if not)\n\n## Data {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(email)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 3,921\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ to_multiple  <fct> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ from         <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ cc           <int> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1,…\n$ sent_email   <fct> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,…\n$ time         <dttm> 2012-01-01 00:16:41, 2012-01-01 01:03:59, 2012…\n$ image        <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ attach       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ dollar       <dbl> 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,…\n$ winner       <fct> no, no, no, no, no, no, no, no, no, no, no, no,…\n$ inherit      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ password     <dbl> 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ num_char     <dbl> 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.…\n$ line_breaks  <int> 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 2…\n$ format       <fct> 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,…\n$ re_subj      <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,…\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ urgent_subj  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ exclaim_mess <dbl> 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4,…\n$ number       <fct> big, small, small, small, none, none, big, smal…\n```\n\n\n:::\n:::\n\n\n## EDA (Ex. 1) {.smaller}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19-logistic-2_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## EDA (Ex. 1) {.smaller}\n\nMean exclamation points by spam/not spam:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  spam  mean_ep\n  <fct>   <dbl>\n1 0        6.51\n2 1        7.32\n```\n\n\n:::\n:::\n\n\n## Linear Model (Ex. 2) {.smaller}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19-logistic-2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThis makes no sense at all.\n\n## Fit Logistic Regression (Ex. 3) {.smaller}\n\nThis is what we have seen already!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_exl_fit <- logistic_reg() |>\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(spam_exl_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  <chr>            <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n```\n\n\n:::\n:::\n\n\n$$\n\\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)\n=\n-2.27\n+\n0.000272\\times exclaim~mess\n$$\n\n## Goal: Predict!! (Ex. 4a) {.smaller}\n\n*What is the probability the email is spam if it contains 10 exclamation points??* Use `predict`!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_email <- tibble(\n  exclaim_mess = 10\n  )\n\nnew_email\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  exclaim_mess\n         <dbl>\n1           10\n```\n\n\n:::\n:::\n\n\n## Goal: Predict!! (Ex. 4a) {.smaller}\n\n*What is the probability the email is spam if it contains 10 exclamation points??* Use `predict`!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_email <- tibble(\n  exclaim_mess = 10\n  )\n\npredict(spam_exl_fit, new_data = new_email, type = \"prob\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  .pred_0 .pred_1\n    <dbl>   <dbl>\n1   0.906  0.0937\n```\n\n\n:::\n:::\n\n\n## Goal: Predict!! (Ex. 4b) {.smaller}\n\n*A probability is nice, but we want an actual decision. Classify the email!!!*\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(spam_exl_fit, new_data = new_email, type = \"class\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  .pred_class\n  <fct>      \n1 0          \n```\n\n\n:::\n:::\n\n\n. . .\n\nThe default behavior is to threshold the probabilities by 0.5.\n\n## Let's use more data (Ex. 5a) {.smaller}\n\nWhy limit ourselves to using exclamation points???\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_fit <- logistic_reg() |>\n  fit(spam ~ time + exclaim_mess + line_breaks, data = email)\n```\n:::\n\n\n## Let's use even more data (Ex. 5b) {.smaller}\n\nWhat about all the predictors???\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_all_fit <- logistic_reg() |>\n  fit(spam ~ ., data = email)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n```\n\n\n:::\n:::\n\n\nThe `.` means *all other variables* .\n\n## Is our model good??? (Ex. 5c) {.smaller}\n\n-   Goal is to evaluate how good our model is.\n-   If you're coding along: pause!! We're going to review concepts first!!\n\n## Reminder: Classification Error {.smaller}\n\nThere are two kinds of mistakes:\n\n![](images/18/confusion-matrix.png)\n\nWe want to avoid both, but there's a trade-off.\n\n## Terms: False negative and positive rates {.smaller}\n\n-   **False negative rate** is the *proportion* of actual positives that were classified as negatives.\n\n-   **False positive rate** is the *proportion* of actual negatives that were classified as positives.\n\n. . .\n\n::: callout-tip\nWe want these to be low!\n:::\n\n## Terms: False negative and positive rates {.smaller}\n\n-   **False negative rate** = $\\frac{FN}{FN + TP}$\n\n-   **False positive rate** = $\\frac{FP}{FP + TN}$\n\n![](images/18/confusion-matrix.png)\n\n## Term: Sensitivity {.smaller}\n\n**Sensitivity** is the *proportion* of actual positives that were correctly classified as positive.\n\n-   Also known as **true positive rate** and **recall**\n\n-   Sensitivity = $\\frac{FN}{FN + TP}$\n\n-   Sensitivity = 1 − False negative rate\n\n-   Useful when false negatives are more \"expensive\" than false positives\n\n::: callout-tip\nWe want this to be high!\n:::\n\n## Term: Specificity {.smaller}\n\n**Specificity** is the *proportion* of actual negatives that were correctly classified as negative\n\n-   Also known as **true negative rate**\n\n-   Specificity = $\\frac{TN}{FP + TN}$\n\n-   Specificity = 1 − False positive rate\n\n-   Useful when false positives are more \"expensive\" than false negatives\n\n::: callout-tip\nWe want this to be high!\n:::\n\n## The augment function {.smaller}\n\nThe `augment` function takes a data frame and \"augments\" it by adding three new columns on the left that describe the model predictions for each row:\n\n::: incremental\n-   `.pred_class`: model prediction ($\\hat{y}$) based on a 50% threshold;\n-   `.pred_0`: model estimate of $P(y=0)$;\n-   `.pred_1`: model estimate of $P(y=1) = 1 - P(y = 0)$.\n:::\n\n## The augment function {.smaller}\n\nThe `augment` function takes a data frame and \"augments\" it by adding three new columns on the left that describe the model predictions for each row:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_aug_all <- augment(spam_all_fit, email)\nspam_aug_all\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3,921 × 24\n   .pred_class .pred_0  .pred_1 spam  to_multiple from     cc\n   <fct>         <dbl>    <dbl> <fct> <fct>       <fct> <int>\n 1 0             0.867 1.33e- 1 0     0           1         0\n 2 0             0.943 5.70e- 2 0     0           1         0\n 3 0             0.942 5.78e- 2 0     0           1         0\n 4 0             0.920 7.96e- 2 0     0           1         0\n 5 0             0.903 9.74e- 2 0     0           1         0\n 6 0             0.901 9.87e- 2 0     0           1         0\n 7 0             1.00  7.89e-12 0     1           1         0\n 8 0             1.00  1.24e-12 0     1           1         1\n 9 0             0.862 1.38e- 1 0     0           1         0\n10 0             0.922 7.76e- 2 0     0           1         0\n# ℹ 3,911 more rows\n# ℹ 17 more variables: sent_email <fct>, time <dttm>, image <dbl>,\n#   attach <dbl>, dollar <dbl>, winner <fct>, inherit <dbl>,\n#   viagra <dbl>, password <dbl>, num_char <dbl>, line_breaks <int>,\n#   format <fct>, re_subj <fct>, exclaim_subj <dbl>,\n#   urgent_subj <fct>, exclaim_mess <dbl>, number <fct>\n```\n\n\n:::\n:::\n\n\n## Calculating the error rates (5c) {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_aug_all |>\n  count(spam, .pred_class) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  spam  .pred_class     n\n  <fct> <fct>       <int>\n1 0     0            3521\n2 0     1              33\n3 1     0             299\n4 1     1              68\n```\n\n\n:::\n:::\n\n\n## Calculating the error rates (5c) {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_aug_all |>\n  count(spam, .pred_class) |>\n  group_by(spam)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n# Groups:   spam [2]\n  spam  .pred_class     n\n  <fct> <fct>       <int>\n1 0     0            3521\n2 0     1              33\n3 1     0             299\n4 1     1              68\n```\n\n\n:::\n:::\n\n\n## Calculating the error rates (5c) {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_aug_all |>\n  count(spam, .pred_class) |>\n  group_by(spam) |>\n  mutate(p = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  <fct> <fct>       <int>   <dbl>\n1 0     0            3521 0.991  \n2 0     1              33 0.00929\n3 1     0             299 0.815  \n4 1     1              68 0.185  \n```\n\n\n:::\n:::\n\n\n## Calculating the error rates (5c) {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_aug_all |>\n  count(spam, .pred_class) |>\n  group_by(spam) |>\n  mutate(p = n / sum(n),\n         decision = case_when(\n            spam == \"0\" & .pred_class == \"0\" ~ \"True negative\",\n            spam == \"0\" & .pred_class == \"1\" ~ \"False positive\",\n            spam == \"1\" & .pred_class == \"0\" ~ \"False negative\",\n            spam == \"1\" & .pred_class == \"1\" ~ \"True positive\"\n        ))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n# Groups:   spam [2]\n  spam  .pred_class     n       p decision      \n  <fct> <fct>       <int>   <dbl> <chr>         \n1 0     0            3521 0.991   True negative \n2 0     1              33 0.00929 False positive\n3 1     0             299 0.815   False negative\n4 1     1              68 0.185   True positive \n```\n\n\n:::\n:::\n\n\nThis is where we have AE14 stop....\n\n## But wait! {.smaller}\n\nAugment uses a default 50% threshold.\n\n. . .\n\nIf we change the classification threshold, we change the classifications, and we change the error rates:\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2-4\"}\nspam_aug_all |>\n  mutate(\n    .pred_class = if_else(.pred_1 <= 0.25, 0, 1)\n  ) |>\n  count(spam, .pred_class) |>\n  group_by(spam) |>\n  mutate(p = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n      p\n  <fct>       <dbl> <int>  <dbl>\n1 0               0  3263 0.918 \n2 0               1   291 0.0819\n3 1               0   172 0.469 \n4 1               1   195 0.531 \n```\n\n\n:::\n:::\n\n\n## Classification threshold: 0.00 {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2-4\"}\nspam_aug_all |>\n  mutate(\n    .pred_class = if_else(.pred_1 <= 0.00, 0, 1)\n  ) |>\n  count(spam, .pred_class) |>\n  group_by(spam) |>\n  mutate(p = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n     p\n  <fct>       <dbl> <int> <dbl>\n1 0               1  3554     1\n2 1               1   367     1\n```\n\n\n:::\n:::\n\n\n## Classification threshold: 0.25 {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2-4\"}\nspam_aug_all |>\n  mutate(\n    .pred_class = if_else(.pred_1 <= 0.25, 0, 1)\n  ) |>\n  count(spam, .pred_class) |>\n  group_by(spam) |>\n  mutate(p = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n      p\n  <fct>       <dbl> <int>  <dbl>\n1 0               0  3263 0.918 \n2 0               1   291 0.0819\n3 1               0   172 0.469 \n4 1               1   195 0.531 \n```\n\n\n:::\n:::\n\n\n## Classification threshold: 0.5 {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2-4\"}\nspam_aug_all |>\n  mutate(\n    .pred_class = if_else(.pred_1 <= 0.50, 0, 1)\n  ) |>\n  count(spam, .pred_class) |>\n  group_by(spam) |>\n  mutate(p = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  <fct>       <dbl> <int>   <dbl>\n1 0               0  3521 0.991  \n2 0               1    33 0.00929\n3 1               0   299 0.815  \n4 1               1    68 0.185  \n```\n\n\n:::\n:::\n\n\n## Classification threshold: 0.75 {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2-4\"}\nspam_aug_all |>\n  mutate(\n    .pred_class = if_else(.pred_1 <= 0.75, 0, 1)\n  ) |>\n  count(spam, .pred_class) |>\n  group_by(spam) |>\n  mutate(p = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  <fct>       <dbl> <int>   <dbl>\n1 0               0  3544 0.997  \n2 0               1    10 0.00281\n3 1               0   339 0.924  \n4 1               1    28 0.0763 \n```\n\n\n:::\n:::\n\n\n## Classification threshold: 1.00 {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2-4\"}\nspam_aug_all |>\n  mutate(\n    .pred_class = if_else(.pred_1 <= 1.00, 0, 1)\n  ) |>\n  count(spam, .pred_class) |>\n  group_by(spam) |>\n  mutate(p = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n     p\n  <fct>       <dbl> <int> <dbl>\n1 0               0  3554     1\n2 1               0   367     1\n```\n\n\n:::\n:::\n\n\n## Let's plot these error rates\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19-logistic-2_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n## ROC curve {.smaller}\n\nIf we repeat this process for \"all\" possible thresholds $0\\leq p^\\star\\leq 1$, we trace out the **receiver operating characteristic curve** (ROC curve), which assesses the model's performance across a range of thresholds:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19-logistic-2_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n## ROC curve {.smaller}\n\n::: task\nWhich corner of the plot indicates the best model performance?\n:::\n\n![](images/20/roc-curve-annotated.png) \n\n. . .\n\nUpper left!\n\n## Model comparison\n\nThe farther up and to the left the ROC curve is, the better the classification accuracy.\nYou can quantify this with the area under the curve.\n\n::: callout-note\nArea under the ROC curve will be our \"quality score\" for comparing logistic regression models.\n:::\n\n## ROC for full model {.smaller}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19-logistic-2_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n## ROC for simple model {.smaller}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19-logistic-2_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n## Should we include a predictor? {.smaller}\n\nTo determine whether we should include a predictor in a model, we should start by asking:\n\n::: incremental\n-   Is it ethical to use this variable?\n    (Or even legal?)\n\n-   Will this variable be available at prediction time?\n\n-   Does this variable contribute to explainability?\n:::\n\n# Data splitting and spending\n\n## We've been cheating! {.smaller}\n\n::: incremental\n-   So far, we've been using all the data we have for building models.\n    In predictive contexts, this would be considered *cheating*.\n\n-   Evaluating model performance for predicting outcomes that were used when building the models is like evaluating your learning with questions whose answers you've already seen.\n:::\n\n## Spending your data {.smaller}\n\nFor predictive models (used primarily in machine learning), we typically split data into training and test sets:\n\n![](images/20/test-train-split-1.svg){fig-align=\"center\"} - The **training set** is used for EDA (plots, summary statistics, etc.)\n\n-   The **training set** is used to estimate model parameters (fit models).\n\n-   The **test set** is used to find an independent assessment of model performance.\n    NEVER look at the test set during training.\n\n## How much to spend? {.smaller}\n\n::: incremental\n-   The more data we spend (use in training), the better estimates we'll get.\n\n-   Spending too much data in training prevents us from computing a good assessment of predictive performance.\n\n-   Spending too much data in testing prevents us from computing a good estimate of model parameters.\n:::\n\n## The initial split {.smaller}\n\nRandomly pick training and testing rows!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20241112)\nemail_split <- initial_split(email)\nemail_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<2940/981/3921>\n```\n\n\n:::\n:::\n\n\n. . .\n\nDefault: 75% training; 25% testing\n\n## The initial split {.smaller}\n\nChange proportion:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20250612)\nemail_split <- initial_split(email, prop = 0.8)\nemail_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<3136/785/3921>\n```\n\n\n:::\n:::\n\n\n## Setting a seed {.smaller}\n\n::: task\nWhat does `set.seed()` do?\n:::\n\n::: incremental\n-   To create that split of the data, R generates \"pseudo-random\" numbers: while they are made to behave like random numbers, their generation is deterministic given a \"seed\".\n\n-   This allows us to reproduce results by setting that seed.\n\n-   Which seed you pick doesn't matter, as long as you don't try a bunch of seeds and pick the one that gives you the best performance.\n:::\n\n## Accessing the data {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_train <- training(email_split)\nemail_test <- testing(email_split)\n```\n:::\n\n\n## The training set {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_train\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3,136 × 21\n   spam  to_multiple from     cc sent_email time                image\n   <fct> <fct>       <fct> <int> <fct>      <dttm>              <dbl>\n 1 0     0           1         0 0          2012-02-18 13:20:54     0\n 2 1     0           1         0 0          2012-03-10 16:43:58     0\n 3 0     1           1         0 0          2012-03-06 08:10:00     0\n 4 1     0           1         0 0          2012-03-18 08:26:41     0\n 5 0     0           1         0 1          2012-03-15 19:47:33     0\n 6 0     0           1         0 1          2012-03-31 08:24:03     0\n 7 0     0           1         0 0          2012-02-16 10:25:22     0\n 8 0     0           1         0 0          2012-02-24 17:18:35     0\n 9 0     1           1         0 1          2012-01-22 03:02:27     0\n10 0     0           1         0 0          2012-02-10 18:46:30     0\n# ℹ 3,126 more rows\n# ℹ 14 more variables: attach <dbl>, dollar <dbl>, winner <fct>,\n#   inherit <dbl>, viagra <dbl>, password <dbl>, num_char <dbl>,\n#   line_breaks <int>, format <fct>, re_subj <fct>,\n#   exclaim_subj <dbl>, urgent_subj <fct>, exclaim_mess <dbl>,\n#   number <fct>\n```\n\n\n:::\n:::\n\n\n## The testing data {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 785 × 21\n   spam  to_multiple from     cc sent_email time                image\n   <fct> <fct>       <fct> <int> <fct>      <dttm>              <dbl>\n 1 0     1           1         1 1          2012-01-01 12:45:21     1\n 2 0     0           1         0 1          2012-01-01 12:23:44     0\n 3 0     0           1         1 1          2012-01-01 17:40:14     0\n 4 0     0           1         0 0          2012-01-01 20:51:24     0\n 5 0     0           1         2 0          2012-01-01 22:07:57     0\n 6 0     0           1         0 0          2012-01-02 08:35:56     0\n 7 0     0           1         0 0          2012-01-02 09:12:51     0\n 8 0     0           1         5 0          2012-01-02 11:48:26     0\n 9 0     1           1         1 0          2012-01-02 09:27:07     0\n10 0     0           1         7 0          2012-01-02 18:07:51     0\n# ℹ 775 more rows\n# ℹ 14 more variables: attach <dbl>, dollar <dbl>, winner <fct>,\n#   inherit <dbl>, viagra <dbl>, password <dbl>, num_char <dbl>,\n#   line_breaks <int>, format <fct>, re_subj <fct>,\n#   exclaim_subj <dbl>, urgent_subj <fct>, exclaim_mess <dbl>,\n#   number <fct>\n```\n\n\n:::\n:::\n\n\n## AE 15\n\n-   Create a train and test split\n-   Fit models\n-   Test and evaluate models\n\n# Washington forests\n\n## Data {.smaller}\n\n-   The U.S. Forest Service maintains machine learning models to predict whether a plot of land is \"forested.\"\n\n-   This classification is important for research, legislation, land management, etc. purposes.\n\n-   Plots are typically remeasured every 10 years.\n\n-   The `forested` dataset contains the most recent measurement per plot.\n\n## Data: `forested` {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7,107 × 19\n   forested  year elevation eastness northness roughness tree_no_tree\n   <fct>    <dbl>     <dbl>    <dbl>     <dbl>     <dbl> <fct>       \n 1 Yes       2005       881       90        43        63 Tree        \n 2 Yes       2005       113      -25        96        30 Tree        \n 3 No        2005       164      -84        53        13 Tree        \n 4 Yes       2005       299       93        34         6 No tree     \n 5 Yes       2005       806       47       -88        35 Tree        \n 6 Yes       2005       736      -27       -96        53 Tree        \n 7 Yes       2005       636      -48        87         3 No tree     \n 8 Yes       2005       224      -65       -75         9 Tree        \n 9 Yes       2005        52      -62        78        42 Tree        \n10 Yes       2005      2240      -67       -74        99 No tree     \n# ℹ 7,097 more rows\n# ℹ 12 more variables: dew_temp <dbl>, precip_annual <dbl>,\n#   temp_annual_mean <dbl>, temp_annual_min <dbl>,\n#   temp_annual_max <dbl>, temp_january_min <dbl>, vapor_min <dbl>,\n#   vapor_max <dbl>, canopy_cover <dbl>, lon <dbl>, lat <dbl>,\n#   land_type <fct>\n```\n\n\n:::\n:::\n\n\n## Data: `forested` {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(forested)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 7,107\nColumns: 19\n$ forested         <fct> Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             <dbl> 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2…\n$ elevation        <dbl> 881, 113, 164, 299, 806, 736, 636, 224, 52,…\n$ eastness         <dbl> 90, -25, -84, 93, 47, -27, -48, -65, -62, -…\n$ northness        <dbl> 43, 96, 53, 34, -88, -96, 87, -75, 78, -74,…\n$ roughness        <dbl> 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 19…\n$ tree_no_tree     <fct> Tree, Tree, Tree, No tree, Tree, Tree, No t…\n$ dew_temp         <dbl> 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6…\n$ precip_annual    <dbl> 466, 1710, 1297, 2545, 609, 539, 702, 1195,…\n$ temp_annual_mean <dbl> 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61,…\n$ temp_annual_min  <dbl> -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.…\n$ temp_annual_max  <dbl> 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 1…\n$ temp_january_min <dbl> -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, …\n$ vapor_min        <dbl> 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 17…\n$ vapor_max        <dbl> 1194, 938, 754, 1164, 1254, 1331, 1275, 944…\n$ canopy_cover     <dbl> 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74,…\n$ lon              <dbl> -118.6865, -123.0825, -122.3468, -121.9144,…\n$ lat              <dbl> 48.69537, 47.07991, 48.77132, 45.80776, 48.…\n$ land_type        <fct> Tree, Tree, Tree, Tree, Tree, Tree, Non-tre…\n```\n\n\n:::\n:::\n\n\n## Outcome and predictors {.smaller}\n\n-   Outcome: `forested` - Factor, `Yes` or `No`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(forested$forested)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Yes\" \"No\" \n```\n\n\n:::\n:::\n\n\n-   Predictors: 18 remotely-sensed and easily-accessible predictors:\n\n    -   numeric variables based on weather and topography\n\n    -   categorical variables based on classifications from other governmental organizations\n\n## `?forested`\n\n<iframe width=\"900\" height=\"500\" src=\"https://simonpcouch.github.io/forested/reference/forested.html\" title=\"forested\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n\n</iframe>\n",
    "supporting": [
      "19-logistic-2_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}