{
  "hash": "4dc606eabf1aa8ef576fe1c7294ad010",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"AE 17:Hypothesis Testing\"\n---\n\nIn this application exercise, we will do hypothesis testing for the slope in the linear model.\n\n## Packages\n\nWe will use **tidyverse** and **tidymodels** for data exploration and modeling, respectively, and the **openintro** package for the data, and the **knitr** package for formatting tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)\n```\n:::\n\n\n## Data\n\nIn this exercise we will be studying predictors of mean household income accross counties in the United States.\nThe contains results for 3142 counties' results from the 2019 American Community Survey (this is all counties at the time).\nThe data set `county_2019` is from the `openintro` package.\nGo ahead and take a look at the data using `glimpse`; you can get more information with `?county_2019`!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\nNow, let's imagine we only had a very small subset of these data to work with.\nThat is, we only have data from a small subset of counties instead of from all counties.\nWhile that is not the case in this data set, we could easily images cases/studies where this might be true.\n\nIn the code below, we set a seed then take a random sample of 25 counties from our `county_2019` data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ncounties_sample <- county_2019 |>\n  sample_n(25)\n```\n:::\n\n\n**Question:** With so little information, can we draw super strong conclusions?\n\n## Plot\n\n**Task**: First, plot the relationship between mean household income `mean_household_income` and `mean_work_travel` for the full data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounty_2019 |>\n  ggplot(aes(x = uninsured, y = mean_household_income)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ae-17-github-A_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n**Task**: Next, plot the relationship between mean household income `mean_household_income` and `uninsured` for the small sample data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncounties_sample |>\n  ggplot(aes(x = uninsured, y = mean_household_income)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ae-17-github-A_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Inference with the small sample dataset\n\n### Point estimate\n\nFirst, compute the point estimate using the small sample dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobserved_fit <- counties_sample |>\n  specify(mean_household_income ~ uninsured) |>\n  fit()\n\nobserved_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  term      estimate\n  <chr>        <dbl>\n1 intercept   79489.\n2 uninsured    -884.\n```\n\n\n:::\n:::\n\n\n### Simulate the null distribution\n\nNow, simulate the null distribution. We are testing $H_0: \\beta_1=0$ versus the alternative $H_A: \\beta_1\\neq 0$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nnull_dist <- counties_sample |>\n  specify(mean_household_income ~ uninsured) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()\n```\n:::\n\n\nNow, we are going to visualize the null distribution. Note that it's centered at zero, because if the null were true and the true slope was in fact zero, we would expect noisy, imperfect estimates of the slope to wiggle around 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist |> \n  filter(term == \"uninsured\") |>\n  ggplot(aes(x = estimate)) + \n  geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ae-17-github-A_files/figure-html/plot-null-dist-1.png){width=672}\n:::\n:::\n\n\n### Where does our actual point estimate fall under the null distribution?\n\nShade the $p$-value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvisualize(null_dist) +\n  shade_p_value(obs_stat = observed_fit, direction = \"two-sided\")\n```\n\n::: {.cell-output-display}\n![](ae-17-github-A_files/figure-html/shade-p-value-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist |>\n  get_p_value(obs_stat = observed_fit, direction = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  term      p_value\n  <chr>       <dbl>\n1 intercept   0.098\n2 uninsured   0.098\n```\n\n\n:::\n:::\n\n\n**Interpretation**: if the null were true (the true slope was zero), then the probability of data as or more extreme than what we saw in about 10%. At a 5% discernibility level, we fail to reject the null. With the data we have, you can't discern with tremendously high confidence whether the null is true or not. We just don't know.\n",
    "supporting": [
      "ae-17-github-A_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}