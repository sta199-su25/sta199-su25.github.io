{
  "hash": "c6e3c34a112acdf41ccea5e2c0c43150",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"AE 17:Hypothesis Testing\"\n---\n\nIn this application exercise, we will do hypothesis testing for the slope in the linear model.\n\n## Packages\n\nWe will use **tidyverse** and **tidymodels** for data exploration and modeling, respectively, and the **openintro** package for the data, and the **knitr** package for formatting tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)\n```\n:::\n\n\n## Data\n\nIn this exercise we will be studying predictors of mean household income accross counties in the United States.\nThe contains results for 3142 counties' results from the 2019 American Community Survey (this is all counties at the time).\nThe data set `county_2019` is from the `openintro` package.\nGo ahead and take a look at the data using `glimpse`; you can get more information with `?county_2019`!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\nNow, let's imagine we only had a very small subset of these data to work with.\nThat is, we only have data from a small subset of counties instead of from all counties.\nWhile that is not the case in this data set, we could easily images cases/studies where this might be true.\n\nIn the code below, we set a seed then take a random sample of 25 counties from our `county_2019` data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ncounties_sample <- county_2019 |>\n  sample_n(25)\n```\n:::\n\n\n**Question:** With so little information, can we draw super strong conclusions?\n\n## Plot\n\n**Task**: First, plot the relationship between mean household income `mean_household_income` and `mean_work_travel` for the full data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n**Task**: Next, plot the relationship between mean household income `mean_household_income` and `uninsured` for the small sample data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n## Inference with the small sample dataset\n\n### Point estimate\n\n**Task**: First, compute the point estimate using the small sample dataset.\n*Tip:* This should be done in the same way we did during our confidence interval lesson (using `specify`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n### Simulate the null distribution\n\nNow, simulate the null distribution.\nWe are testing $H_0: \\beta_1=0$ versus the alternative $H_A: \\beta_1\\neq 0$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nnull_dist <- ________ |>\n  specify(______ ~ _______) |>\n  hypothesize(null =  ________) |>\n  generate(reps = 1000, type = ________) |>\n  fit()\n```\n:::\n\n\nNow, we are going to visualize the null distribution.\nNote that it's centered at zero, because if the null were true and the true slope was in fact zero, we would expect noisy, imperfect estimates of the slope to wiggle around 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist |> \n  filter(______ == ______) |>\n  ggplot(aes(x = _______)) + \n  geom_histogram()\n```\n:::\n\n\n### Where does our actual point estimate fall under the null distribution?\n\nShade the $p$-value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n_______(null_dist) +\n  _______(obs_stat = observed_fit, direction = \"two-sided\")\n```\n:::\n\n\nCompute the $p$-value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist |>\n  _________(obs_stat = observed_fit, direction = \"two-sided\")\n```\n:::\n\n\n**Interpretation**: Explain how we can interpret the p-value here.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}